---
title: 'PSTAT 131: Homework 2'
author: "Lily Li"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(tidymodels)
library(corrplot)
library(readr)
library(yardstick)
tidymodels_prefer()
abalone_data <- read_csv("~/Desktop/PSTAT 131/homework-2/data/abalone.csv") # read dataset through path
```

## Q1

```{r}
abalone_data$age <- abalone_data$rings + 1.5

ggplot(abalone_data, aes(x=age)) +
  geom_histogram(binwidth=1) +
  labs(x="Age") 

summary(abalone_data$age)

corrplot(cor(select_if(abalone_data, is.numeric)), method="number", type="lower")

```

The distribution of age is skewed right with most points centered at the peak around 10 or 11; this tells us that most ages of abalone measured fall slightly on the lower range. There are very large values that could be outliers around the ages of 28 and 30.

# Q2:
```{r}
set.seed(1234) # to reproduce results
data_split <- initial_split(abalone_data, prop = 0.8, strata = rings)
train_data <- training(data_split)
test_data <- testing(data_split)
```

## Q3:

Rings should not be used to predict Age since the value of Age is directly calculated using Rings, thus creating the issue of multicollineairty. 

```{r}
age_recipe <- recipe(age ~ ., data = select(train_data, -rings)) %>%
  step_normalize() %>%
  step_dummy(all_nominal_predictors()) %>%
  step_interact(terms = type~shucked_weight, longest_shell~diameter, shucked_weight~shell_weight)
```

## Q4. 

```{r}
# specify a linear reg object using the "lm" engine
lm_model <- linear_reg() %>% 
  set_engine("lm")
```

## Q5.

```{r}
# use a workflow to pair a model and recipe
lm_wflow <- workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(age_recipe)
```

## Q6.

```{r}
fabalone_pred <-  tibble(longest_shell = 0.50, diameter = 0.10, height = 0.30, whole_weight = 4, shucked_weight = 1, viscera_weight = 2, shell_weight = 1) # hypothetical observation

#fit the linear model to the training set
lm_fit <- linear_reg() %>%
  fit(age ~ ., data = select(train_data, -rings, -type))

age_pred <- predict(lm_fit, new_data = fabalone_pred) # 14.38694
```

## Q7.

```{r}
age_train_res <- predict(lm_fit, new_data = train_data %>% select(-age))
pred_act <- bind_cols(age_train_res, train_data %>% select(age))
# tibble of  predicted values with actual observed ages
pred_act %>% 
  ggplot(aes(x = .pred, y = age)) +
  geom_point(alpha = 0.2) +
  geom_abline(lty = 2) + 
  coord_obs_pred()
age_metrics <- metric_set(rmse, rsq, mae)
age_metrics(pred_act, truth = age, 
                estimate = .pred)
```
$R^2$ estimates how well the regression model predicts actual observed ages. The estimate tells us that 0.5321263 (about half) is the proportion of variability in age is explained by the regression model. This is a low correlation between the predictors and age. RMSE measures how concentrated the data is around the regression line. The value 2.1981612 tells us how far off the age predictions may be from the actual ages. The MAE tells use the average distance from the actual ages and the mean age. This means that the ages are 1.6053366 far from the mean age regardless of direction. Since the points stray from the regression line, linear regression would not be the best model to predict age.



